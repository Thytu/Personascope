Just luck of life. I wasn't even planning to go into the tech field. At first, I was initially planning to join the army. And by just luck of life, I stumbled across tech and I just felt enough with it. So then in tech, I tried different things. I tried cybersecurity. At first, I thought I wanted to do cybersecurity. It was really great, really fun. but I wasn't really a top performer into the field. I also tried DeFi and Web3. I even worked at Kiln formely Skillz, a Web3 slash DeFi company. It was great, paid very well, but I wasn't really in love with the field. And suddenly when I stumbled again, I just had a look of life on AI. that was like, oh wow, I had this magic moment of me realizing that this was what I wanted to do.
So it was a project mixing cybersecurity and AI. But I initially started the project because of the cybersecurity aspect, not because of its AI aspect. We were trying to detect cybersecurity attack on the network using AI model. So we will sniff every network packets on a given network forwarded to an AI model who will predict basically doing an anomaly detection, it will say how weird or not the packet was. And it was kind of a rabbit hole for me trying to improve this AI model to improve my accuracy and security detection. So I fell into this rabbit hole discovering different types of AI models. And I think one thing that really struck me was GAN, Generative Adversarial Network. This idea where you can have two AI models competing on an opposite goal. One trying to fool the other one, and one trying to detect if the other one is trying to fool you or not. basically, if I make it simple. And using GAN, I tried to generate faces, and it was just wow. I was like, oh wow, okay, so there is something magic going on here. And if I GAN, I remember also discovering the reinforcement learning RL. I'm like, holy shit, we can even teach an AI model to play video game if you want to learn to walk and it just showed me how proud and large the horizon was
Well, obviously there are many aspects. The field has evolved a lot in a few years from 2019 compared to now. It's a different world, it's a different field. So what used to be totally incredible is now considered as a commodity. Let's take image generation at first. I was like, holy shit this image is so great it's 100 pixels by 100 pixels and then we can totally generate 4k images and you wouldn't even have a wow moment you would just be like yeah it's good so my starter rates have evolved quite a lot but there's still many topics that interest me if i I have to cite a few, maybe two. One is world model. It's the idea where you can simulate a world inside a model. There's many applications. One use case shown in many papers is obviously video game This idea where you can play a video game not inside a game engine but inside an AI model So basically the AI model has a frame a start frame and it takes as inputs a keystroke, for example, upper arrow, and it will generate the next frame. So with a simple idea, you can see it's Minecraft, for example, where you just take the mouse input and keyboard input, whatever, and it reproduces Minecraft by just generating it. It's super challenging for this model because it requires some consistency across time, some top-roll consistency, but also to have maybe the notion of physics, and physics in a video game is different than physics in reality. So you can see how deep and challenging it can be. But another more concrete application of world model will be robotics. Training and evaluating as well in robotics is super time consuming It a pain in the ass And so a way to take a lead is to create build a very expensive simulation and you will train your model into a simulation as close as possible to reality and then test it into reality. And so, basically doing what we call sim2real. But it requires you to simulate, like to build a simulation for every aspect of the world, which can be quite complex. Or you can use world model. You can just put your robots into this world model and tell the world model, okay, the robot turns right and bam, you're creating training data at infinite scale for your robots and also evaluating your robots in many different fields and scenarios. So that's one aspect, world model, I really love. Another aspect is using LLMs to simulate humans, not in a way where you want to automate the task but in a way where your goal is to mimic as closely as possible someone So it can be someone accent it can be someone behavior someone thinking process And there is many interesting topics in the field There is, if you focus and you simulate one specific person, so companies like Delphi do that, where your whole goal is to simulate the mind of someone, and then you have a library of minds. But you can also imagine on the other side of the spectrum, something way more horizontal, where your goal is not to simulate someone specifically, but rather a population. And then you can also do things very interesting where you can try to do market analysis on AI simulation of a population. And you can see how hugely useful it can be, both for marketing and sales, but also for politics. For example, if you want someone to win election, you can just run a bunch of simulations with different topics and discourse that you will rewrite each time to improve your simulation until you release it into the real world. So that's maybe the two topics that fascinate me the most as of today.
Well, like I said, this topic of AI for human simulation is crazy interesting to me. I started explaining it maybe in December 2024, when I stumbled across a library made by Microsoft that was called Tiny Troop, and that's how I stumbled on this rabbit hole. I found Tiny Troop to be really great, but also quite limiting and frustrating in many aspects. It wasn't hugely minted. It's like, hey, you know what? I will do it myself. So I recreated a better version, according to me, of Tiny Troops. It's called Agentarium. I released it on GitHub. It got 1,000 stars. Also, Hiker News got top 10. And it truly started for me to start a bit whole of reading papers and how do you manage to ensure the quality of your simulation. and I met with some founders working on the same field. And now as of today, I'm being in discussion to gentrify. So it never really left me.
At the time, most libraries were focusing on automating work, rather than focusing on the simulation itself. Meaning, most libraries were focusing on how can you provide more tools to your agent, being able to read your emails, being able to go on the internet, being able to create linear tickets, create pull requests on GitHub, who knows. but very few have given any importance to how close your AI model is to human actions and that's a very different aspect one focus on how many tools you can provide to your agency and the other one focus on how close it is to reality and so what I wanted is to be able to work on the prompt and the interactions between my agents rather than on what actions it could take.
Well, that's obviously an open topic that is unsolved. I haven't really continued working on agent areas since then. It was more once-time projects rather than a long-term thing. So it's fully an open question. There is many research papers on the field that try to correlate LLM's output with human decisions.
Well, it's just very... first, your question is a bit stupid, and second, it's just very different objectives. Just completely two different types of agents. One's goal is to automate work. So to automate work, you need to be able to take actions, and then to take smart actions. So taking phone calls, sending emails, going on Notion, whatever. So the one is making sure that whatever learnings you get from your simulation is accurate and as close as possible to reality. And for this, you don't need your agents to be able to go and notion, read its email or open Google Sheet. You just need to be as accurate as possible. So it just totally, truly,
Well, there is always two schools on it. There's one that provides huge importance to ethical aspects. Bad usage you can get out of a technology. And the other school is who cares? Let's move forward. It's kind of Europe versus China if we want to make it cliche. And more on this school, who cares about it? Let's move forward and see where we go rather than stopping and thinking. Because I think if it's not me, someone else will do it. So the question when you stop your research, your progress, your work, isn't, hey, should we stop? It's, should I stop? And so only you pay the price. So the world will keep moving. Other researchers will keep researching the field. So the only impact will be that you won't be at the forefront anymore, you as individual, but society will keep evolving. So I think everyone has a fight. Mine is to make sure that AI keep making progress and other ones fight or ethical consideration. So there is people who devote their time to the ethical aspects. How can we make AI more ethical and simulation more equal, blah, blah, blah. It's not me. And they spend a huge amount of time trying to ask people like me and other researchers to stop their research, which will never happen.
There are obviously many risks, but as I said earlier, I don't think we can agree with every researcher to just stop research for many reasons. One, for political reasons, maybe you will be able to convince the USA, but you will never be able to convince China, for example. so that's one aspect and you can only convince a nation or a sub-population of researcher but there you will always have some researcher who will continue meaning you will left behind those researchers will take the lead and there is such potential of being the leader in the field that you cannot just afford to not be the leader so you cannot afford to take any break and second is just imagine the positive potential of AI. Let's take AI for drug research. Imagine the number of people we could save if we find a cure to cancer or to AIDS. And each year we postpone this discovery is the number of people who die. So again, here again, we cannot afford to just wait. we have to learn to figure out the ethical considerations fast as we move along

To be fair, I don't think I'm the one who should be asked this question, and I'm not in position to answer your question. Like I said earlier, I think everyone does a job, and this one's not mine. I have very... we, as a human, have very limited time on Earth, and we cannot just afford to... how can someone else work you should ask someone who's focusing on ethic for AI
It's purely by personal interests. That's the question would be what defines your personal interests. That's a harder question. Probably the potential for impact. If we go back to the world model, what it's unlocking is actually robotics. And robotics can just change humanity, humankind's life. Imagine you have robots do your chores, do your blue-collar job, to do anything dangerous for humankind or unpleasant. It can massively reshape the world as we know it. And that's what's in looking world models. So you can see how huge impact it has. On the other side, AI for human simulation also has different aspects more money-focused, let's say. meaning if you're able to simulate humankind you're able to know what product will sell when at what price you're able to know what exact words you should pronounce to become the new presidents of the united states of america you can see how much potential how much personal benefits it can provide and that's this idea of witnessing or observing a huge potential into something that's drives me crazy in a positive way
Skip this question
My mom, she wasn't a huge fan of the idea of me joining the army, obviously. So she forced me to write into every single school presentation she could find. Every single one. And at one point we met two schools. One was called Epita and the other one called Epitech. And I really liked Epita. I really disliked Epitech. And she remembers that. And then life goes on and comes holidays where I wasn't doing anything of my time. And so she force registered me to a two-week training by one of the schools. Only thing is she thought I liked Epitech and not Epita. She just mismatched the names. and Epitech is fully focused on computer science so I was forced to attend two weeks of computer science and damn I just loved it it's finally emerged the logical and rational aspects of me who loves solving puzzles and challenges another one was art this idea where you're crafting something from scratch it's kind of magic to build something using computer science so that was a wow moment
Well, it was this idea that computer science was magic. I just had a PDF I had to follow, where PDF was just a suite of instructions of where to copy-paste to the terminal without thinking too much. And as I copy-pasted stuff to my terminal, new things were happening on my screen. and that was magic to me that I could ask my computer to do anything for me and in theory it was unlimited infinite options
Well, they made me hungry in a good way. Eager to explore what else was doable. So first it was displaying text on a terminal, then using colors to display text, then displaying images, then making a video game, then doing math, then cybersecurity, then finance Web3, DeFi, and then AI as of today.
Wow, hard to answer, luck. Luck was a huge part of my life. People. I've been fortunate to meet incredible people who both taught me hard skills but also soft skills. And I've tried my best to always learn from people. we cannot live an infinite number of lives we have only one life each so what we can do is learn from others people's life and so it can be by reading biography, by reading books but it can also be by just taking the time to talk and to listen to people and as I said I've been fortunate enough to meet incredible people where I tried my best to learn from them And the third will be just curiosity. If you're not curious, you're not making any progress.
Well, first it raised my standards. It's hard to evaluate one data point when you have only one data point because you have no point of comparison. But when you start to have multiple data points, you have context. And when you have context, you can know if you're on the low end or the high, higher end. So it definitely raised my standards. I even quit the job because of it. So it raised my my standards about who I want to work with, about my composition packages, about the topic I wanted to work on, about the intensity I was seeking.
Well, I always believed that brain is an impressive piece of art that is able to do almost anything, as long as you dedicate time and energy. So my school wasn't teaching any AI-related topic. But my brain, like everyone's brain, was able to take the time, like if you're given the time in your day to learn all this stuff. So by seeing people who were able to just learn stuff, It really means that me too, I will be able to learn stuff. And then once you show yourself, once that you're able to learn stuff, you keep that with you forever. I still nowadays have to remind me from time to time what I'm capable of both mentally but also physically by sport. I think it's important, like in vaccines, sometimes you need reminders.
I think the same thing that drove me into computer science is this weird mix of logic and art. Logic because there is quite a lot of mathematics and just logical challenge related to AI. And art because there is something magic to automate something, to detect something, or even to generate something.
That's pretty good. What I'm working right now, and it might change in the near future, is building an evaluation system for how closely an AI copy of someone is to the actual someone. You can split this work in two parts, the retrieval part where you retrieve data that is someone else and the generation part, which is how closely the AI clone talks compared to the actual someone. I'm working on the latter. And more broadly, if you're on Zoom, this whole idea of trying to copy, clone, imitate the human is nearly philosophical, what defines a human. And I consider it as a craft as an art